{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anilkumar-011/Trafficsign_Detection_YoloV5/blob/main/YOLOv5_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# setup"
      ],
      "metadata": {
        "id": "l6yIWOHIm7Mp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "YOLOv5 is a state-of-the-art object detection model that can be used to detect traffic signs in real time. It is a neural network that has been trained on a large dataset of images containing traffic signs. Once trained, YOLOv5 can be used to detect traffic signs in any image or video.\n",
        "\n",
        "To use YOLOv5 for traffic sign detection, you first need to install it. You can do this using the following command:\n",
        "\n",
        "```\n",
        "pip install yolov5\n",
        "```\n",
        "\n",
        "Once YOLOv5 is installed, you can import it into your Python program. You can then use the YOLOv5 API to detect traffic signs in images or videos.\n",
        "\n",
        "The following code shows how to detect traffic signs in an image using YOLOv5:\n",
        "\n",
        "```\n",
        "import yolov5\n",
        "\n",
        "# Load the YOLOv5 model\n",
        "model = yolov5.load('yolov5s.pt')\n",
        "\n",
        "# Load the image\n",
        "image = cv2.imread('image.jpg')\n",
        "\n",
        "# Detect traffic signs in the image\n",
        "detections = model.detect(image)\n",
        "\n",
        "# Print the detected traffic signs\n",
        "for detection in detections:\n",
        "    print(detection)\n",
        "```\n",
        "\n",
        "The `detection` object contains information about the detected traffic sign, such as its bounding box, confidence score, and class label.\n",
        "\n",
        "YOLOv5 is a powerful tool that can be used to detect traffic signs in real time. It can be used to improve the safety of autonomous vehicles and to help drivers comply with traffic laws.\n",
        "\n",
        "Here are some of the benefits of using YOLOv5 for traffic sign detection:\n",
        "\n",
        "* **Real-time detection:** YOLOv5 can detect traffic signs in real time, which makes it ideal for use in autonomous vehicles.\n",
        "* **High accuracy:** YOLOv5 has been shown to be very accurate at detecting traffic signs, even in challenging conditions such as low light and occlusion.\n",
        "* **Easy to use:** YOLOv5 is easy to use and can be integrated into a variety of applications.\n",
        "\n",
        "If you are looking for a powerful and accurate traffic sign detection tool, YOLOv5 is a great option."
      ],
      "metadata": {
        "id": "xbyrfWMogzoJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "zVvNiHaR87qQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wbvMlHd_QwMG"
      },
      "source": [
        "!git clone https://github.com/ultralytics/yolov5  # clone\n",
        "%cd yolov5\n",
        "%pip install -qr requirements.txt  # install\n",
        "\n",
        "import torch\n",
        "import utils\n",
        "display = utils.notebook_init()  # checks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY2VXXXu74w5"
      },
      "source": [
        "\n",
        "# 1. Train\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The train section of YOLOv5 is used to train a custom object detection model. To do this, you will need to first gather a dataset of images that contain the objects you want to detect. You will then need to label each image with the bounding boxes of the objects in the image. Once your dataset is labeled, you can use the YOLOv5 train command to train a model. The train command takes a number of arguments, including the path to your dataset, the batch size, the number of epochs, and the path to a pre-trained model. If you do not specify a pre-trained model, YOLOv5 will start from scratch. The training process can take several hours, depending on the size of your dataset and the number of epochs you specify. Once training is complete, you will have a trained object detection model that can be used to detect objects in new images.\n",
        "\n",
        "Here are some additional tips for training a custom YOLOv5 model:\n",
        "\n",
        "* Use a large dataset. The more data you have, the better your model will be.\n",
        "* Label your data carefully. Make sure that the bounding boxes are accurate and that the labels are correct.\n",
        "* Use a pre-trained model. This will help to speed up the training process and improve the quality of your model.\n",
        "* Train for a sufficient number of epochs. The number of epochs you need to train for will depend on the size of your dataset and the complexity of your model.\n",
        "* Monitor your training progress. Use a tool like TensorBoard to track your model's performance during training. This will help you to identify any problems with your model and make adjustments as needed.\n",
        "\n",
        "With a little patience and effort, you can train a custom YOLOv5 model that can be used to detect objects in new images."
      ],
      "metadata": {
        "id": "fJDVsqvwhKpH"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NcFxRcFdJ_O"
      },
      "source": [
        "!python train.py --img 640 --batch 20 --epochs 150 --data /content/drive/MyDrive/MCP2/DatasetYolov5/customyolov5.yaml --weights yolov5l.pt --cache"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eq1SMWl6Sfn"
      },
      "source": [
        "# 2. Validate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The validate section of YOLOv5 is used to evaluate the performance of a trained object detection model. To do this, you will need to provide the path to the model weights and the path to the validation dataset. The validation dataset is a set of images that were not used to train the model. YOLOv5 will evaluate the model's performance on the validation dataset by calculating the mean average precision (mAP). The mAP is a measure of the model's ability to correctly detect and classify objects in images. A higher mAP indicates a better performing model.\n",
        "\n",
        "The validate command has a number of options that can be used to customize the evaluation process. For example, you can specify the size of the images that will be used for evaluation, the number of classes that the model is expected to detect, and the threshold that will be used to determine whether a detection is considered to be correct.\n",
        "\n",
        "The validate command will output a summary of the model's performance on the validation dataset. This summary includes the mAP for each class, the overall mAP, and the number of images that were evaluated. The validate command can also be used to save the model's performance metrics to a file.\n"
      ],
      "metadata": {
        "id": "-7EwZgbIhXWA"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X58w8JLpMnjH"
      },
      "source": [
        "!python val.py --weights /content/yolov5/runs/train/exp/weights/last.pt --data /content/custom.yaml --img 640 --half"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JnkELT0cIJg"
      },
      "source": [
        "# 3. Detect\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sure, here is a summary of the detect section of YOLOv5:\n",
        "\n",
        "* The detect section of YOLOv5 is used to perform object detection on images, videos, directories, globs, YouTube, webcam, streams, etc.\n",
        "* The detect section can be used with a variety of input formats, including PyTorch, TorchScript, ONNX, OpenVINO, TensorRT, CoreML, TensorFlow SavedModel, TensorFlow GraphDef, TensorFlow Lite, TensorFlow Edge TPU, and PaddlePaddle.\n",
        "* The detect section outputs a list of bounding boxes, confidence scores, and class labels for each detected object.\n",
        "* The detect section can be used to detect a variety of objects, including people, cars, animals, and objects.\n",
        "* The detect section is a powerful tool for object detection and can be used for a variety of applications, such as security, surveillance, and robotics.\n",
        "\n",
        "Here are some additional details about the detect section of YOLOv5:\n",
        "\n",
        "* The detect section uses a single-stage object detection algorithm, which means that it can detect objects in a single pass through the image. This makes the detect section very fast, and it can process images at a rate of around 155 frames per second (fps).\n",
        "* The detect section is trained on the COCO dataset, which is a large dataset of images that contain objects. This training data allows the detect section to accurately detect a variety of objects.\n",
        "* The detect section can be used to detect objects in real time. This makes it a valuable tool for security, surveillance, and robotics applications.\n"
      ],
      "metadata": {
        "id": "sz38hLWkhn6p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python detect.py --weights /content/yolov5/runs/train/exp/weights/best.pt --img 640 --conf 0.25 --source /content/test1.png\n",
        "#image"
      ],
      "metadata": {
        "id": "l-5WJ_RCkFAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zR9ZbuQCH7FX"
      },
      "source": [
        "!python detect.py --weights /content/yolov5/runs/train/exp/weights/best.pt --img 640 --conf 0.25 --source /content/traffic-sign-to-test.mp4\n",
        "#video"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.Save results"
      ],
      "metadata": {
        "id": "ZiNd4Jnld17v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can save your work by using the following command in a zip file format"
      ],
      "metadata": {
        "id": "Qph_lGcohqci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!zip -r /content/yolov5l.zip /content/yolov5\n"
      ],
      "metadata": {
        "id": "YCWvFSand1VN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}